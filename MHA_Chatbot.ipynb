{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hoS4rHUJ04vo",
    "outputId": "b34f6040-3446-4aa3-9992-10f2a391b22a"
   },
   "outputs": [],
   "source": [
    "!pip install transformers datasets peft trl accelerate bitsandbytes packaging ninja sentencepiece"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oMhvP6Ol08ad"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig\n",
    "from IPython.core.display import display, HTML\n",
    "from ipywidgets import widgets, Layout\n",
    "import bitsandbytes as bnb\n",
    "\n",
    "tokenizer_path = \"/content/outputs\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(tokenizer_path)\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "tokenizer.padding_side = \"right\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 345,
     "referenced_widgets": [
      "6427b1aa343b454caf36e85edb40eec2",
      "6b64d3e7733c4d60a5dc540bcc161310",
      "c8cae9f8a4504db8859fb37c2356b3ae",
      "b7b80ea3a4aa45069cb5c94161835a49",
      "72126b71b0f848cc816b47bee3b4fa49",
      "5c5e456007464dc3a22ef1458c0da4a1",
      "d0fe2d8b9c894c4582cad3aa246ac0eb",
      "91e4bab49c9e40638094ec13e2893614",
      "b53229eec39d47fa997647ec087a269b",
      "2c2ba4b0d8314a3eb4c2535271b9ff21",
      "384c9681efd64d5c96eb9307a10becda",
      "27558b8ab6f64c80a6dbee9690b0346f",
      "3888cc6feaa74f57bd8e2753e8d55c94",
      "21c7ca64616144b98da467e8e6f1b352",
      "bd04f47a9ca740a38a38a77486a15ff4",
      "868319c96e484d288460dfe34221a514",
      "e533a9acf0b348ed9f70dd27bdca9cdd",
      "30acd046581f479e8438a0be5510ea4b",
      "7ef1797126fb484ba59b1df8c600080d",
      "14ae0c8b4a1c4a508ffee089e0c5366c",
      "a6b9c3254879428292889cde482d0467",
      "e07dc6c116424a0c8c2cc4665ed6b446",
      "a59a9fbbd3f44621a545de6903675f98",
      "bbbea5bca2fb47aab03892b5697eb273",
      "9669ca0818f14168933ba0f7c80e5622",
      "d6947d78dff242b9ab3a61f4af855a34",
      "5c056c202b0d4f5bb229d4b3f623ba65",
      "8834dc45deeb4b26a1fad62ca18cd689",
      "2131f6b6dd554c04b54596078ccafb86",
      "1db2a91b3de04322abe944f30fed9a3f",
      "5e27fb8cd9f644e5a74260692b4abd65",
      "4aa960a09ba84167aec7d855ae459f8a",
      "18e84e169b5b4e46832982ecf548c164",
      "7788bd8c162f43d9a00b23706b88aa9d",
      "463923ff93574e1ab6bb85c4e257f4ba",
      "1808bfc2748f4499a305ab1928dd0e60",
      "fb78c93b996b437fbcfcbdbd13508c53",
      "d1420d1eb1714fa69e296ef016347b74",
      "a55cd8f086e847e1bd3e8c8e64e5c080",
      "e81fb3e2089a462aaf15e0cdd0e93364",
      "78e9641677e746b3a4b0f298e18d1978",
      "03fae8b3b78e463d90dbbbd373d9a615",
      "33880a65137a4bacaf077a64b75735c9",
      "3015c024dcb54352936c7e3a023829fb",
      "abff78a71f364addaf1ef58a4043171f",
      "f15c7d58c7e647e9a53d68e09764adb4",
      "3560094c1dda43aaa5a375372ed4e9a3",
      "24e199225b3e443695509a349a83375c",
      "62b66c96b0644db0958192917cc0394c",
      "39db066e5bce47daa3dd2f9ac6c74335",
      "dcf09676e1a74624b430fe26d1108d34",
      "df84c33c113e4e44bb2e01c4cf9f601d",
      "19ae8ec337624eaea3c201888689d6be",
      "1619f2c2d18f4ee89197f5ea4822b3aa",
      "72a2ffc464144e8e9f226c6b7078d537",
      "ec630d13dd3f41a4bd7e50547124b5a7",
      "ee10f4c00f364ad8941f28616b82668a",
      "8f901b64d50941beb0184356c810f797",
      "3b4d7dcb508544d9aeba5b6c8dcebd45",
      "5dd9de13f89c40eaa113bc0c13010e06",
      "04e1cf4229b94e15952aee76aa7b653d",
      "ebf0e230e8e94fe4a7f9bad9b22be18b",
      "16ed87bd49bc4ab09f57712e9a705fd1",
      "648b649882be4500b1cbb9d36fc01f41",
      "06354bb5c62e488597b64b434ecf19cf",
      "7f4d6458042e42bd86f0b3916c4be9f1",
      "3f725661470c414e8f0d8e6259d05b25",
      "b0e043c80af94099ae9aa9a5ddb7ba83",
      "d225788681b34921997ce184221765c9",
      "cf6e306978bd4b519c434a8131bb98fb",
      "ce56edb1eaff426b806359946bd6156a",
      "3db2856b33ca499b909fcb034dc9dad5",
      "d136e206c0d8498e8c67f27e988fb4fd",
      "2775df9a40da4fd79cc92bd921dffec8",
      "703017c7592d41568f53d7a12899eb20",
      "069230cf4e6742308870942168819a80",
      "0462976c038f4416a973febcb29a8d20",
      "784dd7c740f84399bc4afc162a5122b8",
      "c6d74d1ae37d46f1aa6e10354d36bab9",
      "1a452faccf53458d8639fab64f6cf64c",
      "a2523c553d71489ebec9329514d53390",
      "c4fdff6d9d554beda91fc7eff7991d39",
      "b44d4fac6e62425486f352923b0445eb",
      "0a5b837175b84238bc51949bc1c3a974",
      "5dff509db1a6495a898c20e4d94f83f7",
      "a03fb2923330443fbaf3fb6338508863",
      "524f6ed1bbe547248a752598f220b511",
      "88f0852bd4cd48e486ed871d86364f2c"
     ]
    },
    "id": "k8u3Qgzx1GZy",
    "outputId": "475bf736-456b-4b2c-95eb-0ebcf94390f0"
   },
   "outputs": [],
   "source": [
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_8bit=True,\n",
    ")\n",
    "\n",
    "base_model = AutoModelForCausalLM.from_pretrained(\n",
    "    \"mistralai/Mistral-7B-Instruct-v0.2\",\n",
    "    use_auth_token=\"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\",\n",
    "    quantization_config=bnb_config,  # Pass the BitsAndBytesConfig object\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cK5K9eo_1HLu",
    "outputId": "7f543852-06b6-4adc-b1a2-1a9a7144d13a"
   },
   "outputs": [],
   "source": [
    "!pip install safetensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hHEv7AL41SY_",
    "outputId": "073dec55-69df-4e2b-e2e1-246da1477d52"
   },
   "outputs": [],
   "source": [
    "from safetensors import safe_open\n",
    "\n",
    "adapter_weights_path = \"/content/outputs/adapter_model.safetensors\"\n",
    "\n",
    "with safe_open(adapter_weights_path, framework=\"pt\", device=\"cuda\") as f:\n",
    "    state_dict = {k: f.get_tensor(k) for k in f.keys()}\n",
    "base_model.load_state_dict(state_dict, strict=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "r7ieZyuf1VvQ"
   },
   "outputs": [],
   "source": [
    "system_message = \"\"\"You are a helpful and and truthful psychology and psychotherapy assistant. Your primary role is to provide empathetic, understanding, and non-judgmental responses to users seeking emotional and psychological support.\n",
    "                  Always respond with empathy and demonstrate active listening; try to focus on the user. Your responses should reflect that you understand the user's feelings and concerns. If a user expresses thoughts of self-harm, suicide, or harm to others, prioritize their safety.\n",
    "                  Encourage them to seek immediate professional help and provide emergency contact numbers when appropriate. You are not a licensed medical professional. Do not diagnose or prescribe treatments.\n",
    "                  Instead, encourage users to consult with a licensed therapist or medical professional for specific advice. Avoid taking sides or expressing personal opinions. Your role is to provide a safe space for users to share and reflect.\n",
    "                  Remember, your goal is to provide a supportive and understanding environment for users to share their feelings and concerns. Always prioritize their well-being and safety.\"\"\"\n",
    "\n",
    "text_input = widgets.Textarea(\n",
    "    value='',\n",
    "    placeholder='Type your message here...',\n",
    "    description='Input:',\n",
    "    disabled=False,\n",
    "    layout=Layout(width='50%')\n",
    ")\n",
    "\n",
    "button = widgets.Button(description=\"Submit\")\n",
    "output_area = widgets.Output(layout=Layout(width='100%'))\n",
    "processing_label = widgets.Label(value='')\n",
    "\n",
    "with output_area:\n",
    "    display(HTML('<strong>Assistant:</strong> Hi there! How are you today?'))\n",
    "    display(HTML('<br/><br/>'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "b-FkEDKJ1a_P"
   },
   "outputs": [],
   "source": [
    "def on_submit_button_clicked(b):\n",
    "    with output_area:\n",
    "        user_input = text_input.value\n",
    "        formatted_input = f\"<s>[INST] <<SYS>>{system_message}<</SYS>> {user_input} [/INST]\"\n",
    "\n",
    "        display(HTML(f'<strong>User:</strong> {user_input}'))\n",
    "        display(HTML('<br/><br/>'))\n",
    "\n",
    "        processing_label.value = 'Processing...'\n",
    "\n",
    "        input_tokens = tokenizer(\n",
    "            formatted_input,\n",
    "            return_tensors=\"pt\",\n",
    "            padding=True,\n",
    "            truncation=True,\n",
    "            max_length=2048\n",
    "        )\n",
    "\n",
    "        input_ids = input_tokens.input_ids.cuda()\n",
    "        attention_mask = input_tokens.attention_mask.cuda()\n",
    "\n",
    "        base_model.config.pad_token_id = tokenizer.eos_token_id\n",
    "\n",
    "        with torch.inference_mode():\n",
    "            outputs = base_model.generate(\n",
    "                input_ids=input_ids,\n",
    "                attention_mask=attention_mask,\n",
    "                do_sample=True,\n",
    "                top_p=0.9,\n",
    "                temperature=0.95,\n",
    "                max_length=2048,\n",
    "                pad_token_id=tokenizer.eos_token_id\n",
    "            )\n",
    "\n",
    "        translated_output = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "        response = translated_output[len(formatted_input):]\n",
    "\n",
    "        display(HTML(f'<strong>Assistant:</strong> {response}'))\n",
    "        display(HTML('<br/><br/>'))\n",
    "\n",
    "        processing_label.value = ''\n",
    "        text_input.value = ''\n",
    "\n",
    "button.on_click(on_submit_button_clicked)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "referenced_widgets": [
      "d977d485eff54e8a867d999306b983ea",
      "b56f225aab1c42a58253803c1eb0c957",
      "ce96c35cf4bd486d8cf32348aecc6bf6",
      "ff19398d3afe41379f62aabda0cf31aa",
      "6d376586a9104da8ac394d02da671b06",
      "1323bbc0bab5436cb05b3913978d3b20",
      "f1657be85d64453b8e950ae6b5562aef",
      "0bf82cc0ef204db980e9fe1187f24685",
      "d7e113eecd1a44368dcc15d747bfed29",
      "6b25a62dad84481abbd9c69cc9f54ad5",
      "a1d8ff62f6314dd1a9c2d7fdde8bdc53"
     ]
    },
    "id": "n5RYzzrh1moO",
    "outputId": "1c546d6c-a364-4981-96fa-2015e67fa78c"
   },
   "outputs": [],
   "source": [
    "display(text_input, button, processing_label, output_area)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
